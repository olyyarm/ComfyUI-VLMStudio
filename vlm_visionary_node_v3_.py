import subprocess
import sys
import re
import comfy.model_management as model_management
import gc
import torch
import requests
import time
import random

class GemmaMultimodalAnalyzer:
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "prompt": ("STRING", { "multiline": True, "default": "" }),
                "system_message": ("STRING", { "multiline": True, "default": 
                    "You are a visual assistant. Analyze the image and answer questions about it."
                }),
                "url": ("STRING", { "multiline": False, "default": "http://127.0.0.1:1234/v1/chat/completions" }),
                "max_tokens": ("INT", {"default": 300, "min": 10, "max": 100000}),
                "temp": ("FLOAT", {"default": 0.7, "min": 0, "max": 1, "step": 0.05}),
                "top_p": ("FLOAT", {"default": 0.95, "min": 0, "max": 1, "step": 0.01}),
            },
            # –ê –∑–¥–µ—Å—å –¥–µ–ª–∞–µ–º –ø—Ä–∏—ë–º –∫–∞—Ä—Ç–∏–Ω–∫–∏ –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–º. –ï—Å–ª–∏ –Ω—É–∂–Ω–æ ‚Äî —Å–¥–µ–ª–∞–π—Ç–µ required
            "optional": {
                "image": ("IMAGE",),
            }
        }

    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("generated_text",)
    FUNCTION = "generateText"
    CATEGORY = "LMStudio"

    def generateText(self, 
                     prompt, 
                     system_message, 
                     url, 
                     max_tokens, 
                     temp, 
                     top_p,
                     image=None):
        """
        –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è: –µ—Å–ª–∏ –∫–∞—Ä—Ç–∏–Ω–∫–∞ –ø–æ–¥–∞–Ω–∞, –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ base64
        –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –µ—ë –≤–º–µ—Å—Ç–µ —Å prompt. –ï—Å–ª–∏ –∫–∞—Ä—Ç–∏–Ω–∫–∏ –Ω–µ—Ç, —à–ª—ë–º —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç.
        """
        if image is not None:
            # –ü—Ä–æ–≤–µ—Ä–∏–º —Ñ–æ—Ä–º–∞—Ç (—É–±–µ–¥–∏–º—Å—è, —á—Ç–æ —ç—Ç–æ –Ω–µ –ª–∞—Ç–µ–Ω—Ç –Ω–∞ 768 –∫–∞–Ω–∞–ª–æ–≤)
            self.validate_image(image)
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ base64 –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ LLM
            image_data = self.tensor_to_base64(image)
        else:
            image_data = None

        # –°—Ñ–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å –∫ LLM (Gemma-3-12b-it)
        description = self.call_api(
            prompt_text = prompt,
            system_message = system_message,
            url = url,
            max_tokens = max_tokens,
            temp = temp,
            top_p = top_p,
            image_data = image_data
        )

        return (description,)

    def validate_image(self, tensor):
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ —ç—Ç–æ 4D —Ç–µ–Ω–∑–æ—Ä —Å 1, 3 –∏–ª–∏ 4 –∫–∞–Ω–∞–ª–∞–º–∏,
        –∞ –Ω–µ –ª–∞—Ç–µ–Ω—Ç —Å 768 –∫–∞–Ω–∞–ª–∞–º–∏.
        """
        if tensor.dim() != 4:
            raise ValueError("Invalid image format: expected a 4D tensor (B, C, H, W) or (B, H, W, C).")

        c1 = tensor.shape[1]
        c2 = tensor.shape[3]
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –ª–∞—Ç–µ–Ω—Ç –ª–∏ (768 –∫–∞–Ω–∞–ª–æ–≤)
        if c1 in [1,3,4] or c2 in [1,3,4]:
            return
        else:
            raise ValueError(
                f"Invalid number of channels in image: {tensor.shape}. "
                "Expected 1, 3, or 4 channels. Perhaps you fed a latent (768 channels)?"
            )

    def tensor_to_base64(self, tensor):
        """
        –ü–µ—Ä–µ–≤–æ–¥–∏—Ç ComfyUI-—Ñ–æ—Ä–º–∞—Ç [B, C, H, W] –∏–ª–∏ [B, H, W, C] 
        –≤ base64-encoded PNG.
        """
        import torch
        from torchvision.transforms import ToPILImage
        import io, base64

        # –ï—Å–ª–∏ [B, H, W, C], –º–µ–Ω—è–µ–º –Ω–∞ [B, C, H, W]
        if tensor.shape[1] not in [1,3,4] and tensor.shape[3] in [1,3,4]:
            tensor = tensor.permute(0, 3, 1, 2)
        
        # –°–∂–∏–º–∞–µ–º [0..1] float -> [0..255] byte
        tensor = torch.clamp(tensor * 255.0, 0, 255).byte()

        pil_img = ToPILImage()(tensor[0].cpu())  # –ë–µ—Ä—ë–º –ø–µ—Ä–≤—É—é –∫–∞—Ä—Ç–∏–Ω–∫—É –∏–∑ –±–∞—Ç—á–∞
        buf = io.BytesIO()
        pil_img.save(buf, format="PNG")
        return base64.b64encode(buf.getvalue()).decode("utf-8")

    def build_payload(self, prompt_text, system_message, image_data, temp, max_tokens, top_p):
        """
        –°–æ–±–∏—Ä–∞–µ–º JSON, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–Ω–∏–º–∞–µ—Ç –≤–∞—à–∞ LLM gemma-3-12b-it
        (—É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–æ—Ä–º–∞—Ç messages —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å —Ç–µ–º, 
        –∫–∞–∫ LM Studio/Gemma —Ä–µ–∞–ª—å–Ω–æ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ + —Ç–µ–∫—Å—Ç).
        """
        user_content = []
        user_content.append({"type": "text", "text": prompt_text})

        if image_data:
            user_content.append({
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/png;base64,{image_data}"
                }
            })

        payload = {
            "messages": [
                {"role": "system", "content": system_message},
                {"role": "user",   "content": user_content}
            ],
            "temperature": temp,
            "max_tokens": max_tokens,
            "top_p": top_p
        }
        return payload

    def call_api(self, prompt_text, system_message, url, max_tokens, temp, top_p, image_data):
        """
        –û—Ç–ø—Ä–∞–≤–ª—è–µ–º POST-–∑–∞–ø—Ä–æ—Å –Ω–∞ LMStudio-endpoint —Å –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–µ–∫—Å—Ç-–æ—Ç–≤–µ—Ç.
        """
        import json

        payload = self.build_payload(
            prompt_text, 
            system_message, 
            image_data,
            temp,
            max_tokens,
            top_p
        )

        print(f"API Call: {url}")
        print("Request Payload:", json.dumps(payload, indent=2))

        try:
            response = requests.post(url, json=payload)
            if response.status_code == 200:
                result_json = response.json()
                # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ LLM Studio –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —ç—Ç–æ –ø–æ–ª–µ
                return result_json["choices"][0]["message"]["content"]
            else:
                err = f"API error {response.status_code}: {response.text}"
                print(err)
                return err
        except Exception as e:
            err = f"Request error: {str(e)}"
            print(err)
            return err

# –î–µ–ª–∞–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–º –Ω–∞—à –∫–ª–∞—Å—Å –≤ ComfyUI
NODE_CLASS_MAPPINGS = {
    "GemmaMultimodalAnalyzer": GemmaMultimodalAnalyzer
}
NODE_DISPLAY_NAME_MAPPINGS = {
    "GemmaMultimodalAnalyzer": "üîÆ Gemma Multimodal Analyzer"
}
